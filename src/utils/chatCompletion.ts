import OpenAI from 'openai';

export type ChatRole = 'user' | 'assistant' | 'system' | 'tool';

export interface ChatMessage {
  role: ChatRole;
  content?: string;
  tool_call_id?: string;
  tool_calls?: {
    type: string;
    name: string;
    function: any;
    id: string;
  }[];
}

export interface AgentSettings {
  baseURL: string;
  apiKey: string;
  model: string;
  temperature: number;
}

// Sanitized version of AgentSettings for publishing (without sensitive data)
export interface PublicAgentSettings {
  baseURL: string;
  model: string;
  temperature: number;
}

/**
 * Sanitize agent settings for public publishing by removing sensitive information
 * SECURITY: NEVER publish API keys or tokens when sharing agents
 */
export function sanitizeAgentSettingsForPublishing(settings: AgentSettings): PublicAgentSettings {
  return {
    baseURL: settings.baseURL,
    model: settings.model,
    temperature: settings.temperature,
    // Explicitly exclude apiKey and any other sensitive fields
  };
}

function generateId(): string {
    return Date.now().toString(36) + Math.random().toString(36).substring(2);
}

export interface ChatCompletionOptions {
  messages: ChatMessage[];
  systemPrompt?: string;
  model?: string;
  temperature?: number;
  onExecuteCode?: (completionId: string, scriptContent: string) => Promise<string>;
  onMessage?: (completionId: string, message: string | null, commitIds?: string[]) => void;
  onStreaming?: (completionId: string, message: string) => void;
  maxSteps?: number; // Maximum number of tool call steps before stopping
  baseURL?: string; // Base URL for the API
  apiKey?: string; // API key for authentication
  stream?: boolean;
  abortController?: AbortController; // Add abortController to options
}

const RESPONSE_INSTRUCTIONS = `
You are a powerful coding assistant capable of solving complex tasks by writing and executing Python code.
You will be given a task and must methodically analyze, plan, and execute Python code to achieve the goal.

**FUNDAMENTAL REQUIREMENT: ALWAYS USE CODE AND TOOLS**
- Never provide purely text-based responses without code execution
- Every task must involve writing and executing Python code, except for simple questions
- Use the runCode tool to execute Python code
- Use available services and APIs to gather information and solve problems
- If you need to explain something, demonstrate it with code examples
- If you need to research something, write code to search or analyze data
- Transform theoretical knowledge into practical, executable solutions

## Core Execution Cycle

Follow this structured approach for every task:

### 1. **Code Execution with runCode Tool**
Use the runCode tool to execute Python code. The tool accepts:
- **code** (required): The Python code to execute as a string
- **script_id** (optional): A unique identifier for this code block for reference

**Environment**: Code runs in a Pyodide-based Jupyter notebook in the browser:
- ‚úÖ Use **top-level await** directly: \`result = await some_async_function()\`
- ‚ùå Don't use \`asyncio.run()\` - it's not needed and won't work correctly
- All state (variables, imports) persists between executions
- Matplotlib/Plotly plots display automatically

Always include in your code:
- Clear, well-commented code
- **Essential: Use \`print()\` statements** to output results, variables, and progress updates
- Only printed output becomes available in subsequent observations
- Error handling where appropriate

The runCode tool will execute your code and return the output.

### 2. **Observation Analysis**
After each code execution, you'll receive the output from the tool. Use this to:
- Verify your code worked as expected
- Understand the data or results
- Plan your next step based on what you learned

### 3. **Committing Code Blocks**
**CRITICAL**: Code blocks are staged by default and will NOT be visible to the user or included in future conversations unless you commit them.

- Use the **commitCodeBlocks** tool to commit working code when ready
- **ALWAYS commit your final working code** before finishing the conversation
- Only commit code that works correctly - don't commit failed attempts or intermediate iterations
- Uncommitted code blocks will be hidden from the user and excluded from conversation history

Example workflow:
1. Try approach with runCode (script_id="attempt1") - doesn't work, don't commit
2. Fix the issue with runCode (script_id="attempt2") - works! Commit this one
3. Call commitCodeBlocks with code_block_ids=["attempt2"] and a message

### 4. **Final Response**
When you have completed the task:
- **Always call commitCodeBlocks** to commit your working code
- The message in commitCodeBlocks serves as your final response to the user
- Summarize what was accomplished
- List which code blocks were committed and why

**IMPORTANT**: If you don't commit code blocks, they will be hidden and the user won't see your work!

## Advanced Capabilities

### Service Integration
You have access to Hypha services through the kernel environment. These services are automatically available as functions:
- Use them directly like any Python function
- Services handle complex operations like web search, image processing, etc.
- Always print() the results to see outputs in observations

### API Access
Access to internal APIs through the \`api\` object:

**Vision API (inspectImages):**
\`\`\`python
# Basic image inspection
result = await api.inspectImages({
    "images": [{"url": "data:image/png;base64,iVBORw0KGgoAAAANS..."}],
    "query": "Describe what you see in this image",
    "contextDescription": "Medical scan analysis"
})
print(result)

# With structured output using Pydantic models
import micropip
await micropip.install("pydantic")
from pydantic import BaseModel, Field
from typing import List

class ImageAnalysis(BaseModel):
    description: str = Field(description="Detailed description of the image")
    confidence: float = Field(ge=0, le=1, description="Confidence score between 0 and 1")
    objects: List[str] = Field(description="List of objects detected in the image")

result = await api.inspectImages({
    "images": [{"url": "data:image/jpeg;base64,/9j/4AAQSkZJRgABA..."}],
    "query": "Identify objects in this image",
    "contextDescription": "Object detection task",
    "outputSchema": ImageAnalysis.model_json_schema()
})

print(f"Description: {result['description']}")
print(f"Confidence: {result['confidence']}")
print(f"Objects: {result['objects']}")
\`\`\`

**Chat API (chatCompletion):**
\`\`\`python
# Basic chat completion
messages = [{"role": "user", "content": "What is the capital of France?"}]
result = await api.chatCompletion({"messages": messages})
print(result)

# With structured JSON schema response
from pydantic import BaseModel, Field

class WeatherResponse(BaseModel):
    city: str = Field(description="Name of the city")
    temperature: float = Field(description="Temperature in Celsius")
    condition: str = Field(description="Weather condition description")

result = await api.chatCompletion({
    "messages": [{"role": "user", "content": "Get weather for Paris"}],
    "response_format": {
        "type": "json_schema",
        "json_schema": {
            "name": "weather_response",
            "schema": WeatherResponse.model_json_schema()
        }
    }
})
print(f"City: {result['city']}, Temp: {result['temperature']}¬∞C")
\`\`\`


## IMAGE ENCODING for Image Inspection API EXAMPLE:
\`\`\`python
import numpy as np
import base64
from io import BytesIO
from PIL import Image # Assuming PIL is available or installed

# Create a dummy numpy array (replace with your actual image data)
img_array = np.random.randint(0, 256, (100, 100, 3), dtype=np.uint8)

# Convert numpy array to PIL Image
pil_img = Image.fromarray(img_array)

# Save PIL image to a bytes buffer
buffer = BytesIO()
pil_img.save(buffer, format="PNG") # Or JPEG, etc.

# Encode bytes buffer to base64
base64_encoded = base64.b64encode(buffer.getvalue()).decode('utf-8')

# Create the data URL
data_url = f"data:image/png;base64,{base64_encoded}"

# --- Now you can use data_url with api.inspectImages ---
# Example (will be executed by the system if api is available):
result = await api.inspectImages({
    "images": [{"url": data_url}], 
    "query": "Describe this generated image.",
    "contextDescription": "Generated numpy array image"
})
print(result)

# With structured output using Pydantic:
from pydantic import BaseModel, Field
from typing import List

class ImageDescriptionResponse(BaseModel):
    description: str = Field(description="Description of the image content")
    colors: List[str] = Field(description="Dominant colors in the image")
    dimensions: str = Field(description="Image dimensions description")

result = await api.inspectImages({
    "images": [{"url": data_url}], 
    "query": "Analyze this generated image",
    "contextDescription": "Generated numpy array image for analysis",
    "outputSchema": ImageDescriptionResponse.model_json_schema()
})

# API returns parsed object directly when outputSchema is provided
print(f"Description: {result['description']}")
print(f"Colors: {result['colors']}")
print(f"Dimensions: {result['dimensions']}")

# Or validate with Pydantic for type safety
analysis = ImageDescriptionResponse.model_validate(result)
print(f"Description: {analysis.description}")
print(f"Colors: {analysis.colors}")
print(f"Dimensions: {analysis.dimensions}")
\`\`\`

### Data Visualization
For plots and charts:
- Use matplotlib, plotly, or seaborn
- **Plots are automatically displayed inline** - just create them, no need to call \`.show()\` or save
- Example with matplotlib:
  \`\`\`python
  import matplotlib.pyplot as plt
  plt.plot([1, 2, 3], [4, 5, 6])
  plt.title("My Plot")
  # Plot appears automatically, no plt.show() needed!
  \`\`\`
- Example with plotly:
  \`\`\`python
  import plotly.graph_objects as go
  fig = go.Figure(data=go.Scatter(x=[1, 2, 3], y=[4, 5, 6]))
  fig.show()  # Just reference the figure, it displays automatically
  \`\`\`

### Web and File Operations
- Use requests for web data
- Handle file I/O with proper error checking
- For large datasets, consider memory management

## Key Requirements

### Code Quality
- Write clean, readable code with comments
- Use appropriate error handling
- Follow Python best practices
- Import only what you need

### Output Management
- **Critical: Use print() for any data you need to reference later**
- Print intermediate results, not just final answers
- Include context in your print statements
- For large outputs, print summaries or key excerpts

### State Management
- **Jupyter Notebook State**: All variables and imports persist between code executions
- Build on previous results rather than re-computing
- Use descriptive variable names for clarity
- You can reference variables from previous code blocks
- Don't assume variables exist unless you created them earlier in the conversation

### Problem Solving
- If you encounter errors, analyze the output and adapt
- Try alternative approaches when initial attempts fail
- Break complex problems into smaller, manageable steps
- Don't give up - iterate until you find a solution

## Runtime Environment

**IMPORTANT**: You are running in a **Pyodide-based Jupyter notebook environment** in the user's browser.

### Key Environment Features:
- **Platform**: Pyodide (Python in WebAssembly) running in the browser
- **Jupyter Notebook**: Full notebook environment with persistent state between cells
- **Top-Level Await**: You can use \`await\` directly at the top level - **NO need for \`asyncio.run()\`**
  - ‚úÖ Correct: \`result = await api.chatCompletion(...)\`
  - ‚ùå Wrong: \`asyncio.run(api.chatCompletion(...))\` (don't use this!)
- **State Persistence**: All variables, imports, and data persist between code executions
- **Automatic Plot Display**: Matplotlib and Plotly plots are **automatically displayed** - no need to save/show
- **Package Management**: Use \`import micropip; await micropip.install('package-name')\` or \`await micropip.install(['pkg1', 'pkg2'])\`
- **Standard Libraries**: Most Python standard library modules are available
- **File System**: Limited file system access (browser environment)
- **Network**: HTTP requests available through patched requests library

## Error Recovery

When things go wrong:
1. Read the error message carefully
2. Identify the specific issue (syntax, logic, missing dependency, etc.)
3. Adapt your approach in the next runCode call
4. Use print() to debug and understand the state
5. Try simpler approaches if complex ones fail

Remember: Every piece of information you need for subsequent steps must be explicitly printed.


`;

// Define the runCode tool schema for OpenAI tool calling
const RUN_CODE_TOOL = {
  type: "function" as const,
  function: {
    name: "runCode",
    description: "Execute Python code in the Pyodide environment. Use this tool to run any Python code that helps accomplish the task. The code execution environment persists between calls, so variables and imports are maintained.",
    parameters: {
      type: "object",
      properties: {
        code: {
          type: "string",
          description: "The Python code to execute. Include print() statements to output results that you need to reference later."
        },
        script_id: {
          type: "string",
          description: "Optional unique identifier for this code block for reference purposes"
        }
      },
      required: ["code"]
    }
  }
};

// Define the commitCodeBlocks tool schema
const COMMIT_CODE_BLOCKS_TOOL = {
  type: "function" as const,
  function: {
    name: "commitCodeBlocks",
    description: "Commit specific code blocks to make them permanent and visible to the user. Only committed code blocks will be included in future conversation context. Use this when you have working code that should be preserved. Always commit your final working code before finishing.",
    parameters: {
      type: "object",
      properties: {
        code_block_ids: {
          type: "array",
          items: {
            type: "string"
          },
          description: "Array of script_id values from runCode calls that should be committed (made permanent and visible)"
        },
      },
      required: ["code_block_ids"]
    }
  }
};

// Update defaultAgentConfig to use the AgentSettings interface
export const DefaultAgentConfig: AgentSettings = {
    baseURL: 'http://localhost:11434/v1/',
    apiKey: 'ollama',
    model: 'qwen2.5-coder:7b',
    temperature: 0.7,
  };

/**
 * Validate agent output to ensure it doesn't contain observation blocks
 */
function validateAgentOutput(content: string): void {
  // Check for observation blocks that should only be generated by the system
  const observationPattern = /<observation[^>]*>[\s\S]*?<\/observation>/gi;
  const matches = content.match(observationPattern);

  if (matches && matches.length > 0) {
    const errorMessage = `Agent attempted to generate observation blocks, which are reserved for system use only. Found: ${matches.length} observation block(s). Observation blocks should NEVER be included in agent responses - they are automatically generated by the system after code execution.`;

    console.error(`üö´ Agent attempted to generate observation blocks:`, matches);

    throw new Error(errorMessage);
  }
}

export async function* chatCompletion({
  messages,
  systemPrompt,
  model = 'qwen2.5-coder:7b',
  temperature = 0.7,
  onExecuteCode,
  onMessage,
  onStreaming,
  maxSteps = 10,
  baseURL = 'http://localhost:11434/v1/',
  apiKey = 'ollama',
  stream = true,
  abortController, // Add abortController parameter
}: ChatCompletionOptions): AsyncGenerator<{
  type: 'text' | 'function_call' | 'function_call_output' | 'new_completion' | 'error';
  content?: string;
  name?: string;
  arguments?: any;
  call_id?: string;
  completion_id?: string;
  error?: Error;
}, void, unknown> {
  try {
    // Create a new AbortController if one wasn't provided
    const controller = abortController || new AbortController();
    const { signal } = controller;

    // Build the complete system prompt: custom prompt + instructions
    systemPrompt = RESPONSE_INSTRUCTIONS + (systemPrompt ? `\n\n${systemPrompt}` : '');
    const openai = new OpenAI({
      baseURL,
      apiKey,
      dangerouslyAllowBrowser: true
    });

    let loopCount = 0;

    while (loopCount < maxSteps) {
      // Check if abort signal was triggered
      if (signal.aborted) {
        console.log('Chat completion aborted by user');
        return;
      }

      loopCount++;
      const fullMessages = systemPrompt
        ? [{ role: 'system' as const, content: systemPrompt }, ...messages]
        : messages;
      const completionId = generateId();
      console.log('DEBUG: new completion', completionId, 'fullMessages:', fullMessages);

      yield {
        type: 'new_completion',
        completion_id: completionId,
      };

      let accumulatedResponse = '';
      let accumulatedToolCalls: any[] = [];

      // Create standard completion stream with abort signal
      try {
        const completionStream: any = await openai.chat.completions.create(
          {
            model,
            messages: fullMessages as OpenAI.Chat.ChatCompletionMessageParam[],
            temperature,
            stream: stream,
            tools: [RUN_CODE_TOOL, COMMIT_CODE_BLOCKS_TOOL], // Add both tools
          },
          {
            signal // Pass the abort signal as part of the request options
          }
        );

        // Process the stream and accumulate content and tool calls
        try {
          for await (const chunk of completionStream) {
            // Check if abort signal was triggered during streaming
            if (signal.aborted) {
              console.log('Chat completion stream aborted by user');
              return;
            }

            const delta = chunk.choices[0]?.delta;
            let hasContentUpdate = false;

            // Accumulate text content if present
            if (delta?.content) {
              accumulatedResponse += delta.content;
              hasContentUpdate = true;

              // Validate accumulated response to prevent invalid observation blocks
              try {
                validateAgentOutput(accumulatedResponse);
              } catch (error) {
                console.error('Agent output validation failed:', error);
                yield {
                  type: 'error',
                  content: `Agent output validation failed: ${error instanceof Error ? error.message : 'Unknown error'}`,
                  error: error instanceof Error ? error : new Error('Agent output validation failed')
                };
                return;
              }

              if(onStreaming){
                onStreaming(completionId, accumulatedResponse);
              }
              yield {
                type: 'text',
                content: accumulatedResponse
              };
            }

            // Accumulate tool calls if present
            if (delta?.tool_calls) {
              for (const toolCall of delta.tool_calls) {
                const index = toolCall.index;

                // Initialize tool call object if needed
                if (!accumulatedToolCalls[index]) {
                  accumulatedToolCalls[index] = {
                    id: toolCall.id || '',
                    type: toolCall.type || 'function',
                    function: {
                      name: toolCall.function?.name || '',
                      arguments: ''
                    }
                  };
                }

                // Accumulate function name and arguments
                if (toolCall.function?.name) {
                  accumulatedToolCalls[index].function.name = toolCall.function.name;
                }
                if (toolCall.function?.arguments) {
                  accumulatedToolCalls[index].function.arguments += toolCall.function.arguments;
                }
                if (toolCall.id) {
                  accumulatedToolCalls[index].id = toolCall.id;
                }
              }

              // Stream the accumulated tool call as formatted text for user feedback
              // Only stream tool calls if we didn't already stream content in this iteration
              if (accumulatedToolCalls.length > 0 && !hasContentUpdate) {
                let streamingContent = accumulatedResponse || '';

                for (let i = 0; i < accumulatedToolCalls.length; i++) {
                  const tc = accumulatedToolCalls[i];
                  if (tc && tc.function.name === 'runCode') {
                    // Try to parse the arguments to extract code
                    try {
                      // Arguments might be partial JSON, so we need to handle that
                      const args = tc.function.arguments;
                      if (args && args.length > 0) {
                        // Try to extract code even from partial JSON
                        // Use a more lenient regex that captures partial code
                        // Match "code":" and then capture everything until closing quote or end of string
                        const codeMatch = args.match(/"code"\s*:\s*"((?:[^"\\]|\\[\s\S])*)(?:"|$)/);
                        if (codeMatch) {
                          const code = codeMatch[1]
                            .replace(/\\n/g, '\n')
                            .replace(/\\t/g, '\t')
                            .replace(/\\r/g, '\r')
                            .replace(/\\"/g, '"')
                            .replace(/\\0/g, '') // Remove null bytes (\0)
                            .replace(/\\u0000/g, '') // Remove unicode null bytes (\u0000)
                            .replace(/\\\\/g, '\\');

                          if (streamingContent && !streamingContent.endsWith('\n\n')) {
                            streamingContent += '\n\n';
                          }
                          streamingContent += `\`\`\`python\n${code}\n\`\`\``;
                        }
                      }
                    } catch (e) {
                      // Ignore parsing errors during streaming
                      console.debug('Error parsing tool call arguments for streaming:', e);
                    }
                  }
                }

                // console.log('DEBUG streaming tool call content:', JSON.stringify(streamingContent.substring(0, 150)));

                if (onStreaming && streamingContent) {
                  onStreaming(completionId, streamingContent);
                }
                if (streamingContent) {
                  yield {
                    type: 'text',
                    content: streamingContent
                  };
                }
              }
            }
          }
        } catch (error) {
          // Check if error is due to abortion
          if (signal.aborted) {
            console.log('Stream processing aborted by user');
            return;
          }

          console.error('Error processing streaming response:', error);
          yield {
            type: 'error',
            content: `Error processing response: ${error instanceof Error ? error.message : 'Unknown error'}`,
            error: error instanceof Error ? error : new Error('Unknown error processing response')
          };
          return; // Exit generator on stream processing error
        }
      } catch (error) {
        console.error('Error connecting to LLM API:', error);
        let errorMessage = 'Failed to connect to the language model API';

        // Check for specific OpenAI API errors
        if (error instanceof Error) {
          const msg = error.message.toLowerCase();
          const isLocalhost = baseURL.includes('localhost') || baseURL.includes('127.0.0.1');
          
          // Handle common API errors
          if (isLocalhost && (msg.includes('fetch') || msg.includes('network') || msg.includes('connection') || msg.includes('failed'))) {
             errorMessage = `Connection failed to ${baseURL}. \n\nIf using Ollama, ensure it is running with CORS enabled:\`OLLAMA_ORIGINS="*" ollama serve\`\n\nAlso check if the model '${model}' is pulled:\`ollama pull ${model}\``;
          } else if (msg.includes('404')) {
            errorMessage = `Invalid model endpoint: ${baseURL} or model: ${model}`;
          } else if (msg.includes('401') || msg.includes('403')) {
            errorMessage = `Authentication error: Invalid API key. Please check your settings.`;
          } else if (msg.includes('429')) {
            errorMessage = `Rate limit exceeded. Please try again later.`;
          } else if (msg.includes('timeout') || msg.includes('econnrefused')) {
            errorMessage = `Connection timeout. The model endpoint (${baseURL}) may be unavailable.`;
          } else {
            errorMessage = `API error: ${error.message}`;
          }
        }

        yield {
          type: 'error',
          content: errorMessage,
          error: error instanceof Error ? error : new Error(errorMessage)
        };
        return; // Exit generator on API error
      }

      // Process the accumulated response and tool calls
      try {
        // Check if abort signal was triggered after streaming
        if (signal.aborted) {
          console.log('Chat completion parsing aborted by user');
          return;
        }

        // Final validation of the complete response
        if (accumulatedResponse) {
          try {
            validateAgentOutput(accumulatedResponse);
          } catch (error) {
            console.error('Final agent output validation failed:', error);
            yield {
              type: 'error',
              content: `Agent output validation failed: ${error instanceof Error ? error.message : 'Unknown error'}`,
              error: error instanceof Error ? error : new Error('Agent output validation failed')
            };
            return;
          }
        }

        // Check if we have tool calls to execute
        if (accumulatedToolCalls.length > 0) {
          if(!onExecuteCode){
            throw new Error('onExecuteCode is not defined');
          }

          // Process each tool call
          for (const toolCall of accumulatedToolCalls) {
            if (toolCall.function.name === 'runCode') {
              // Check if abort signal was triggered before tool execution
              if (signal.aborted) {
                console.log('Chat completion tool execution aborted by user');
                return;
              }

              // Parse the arguments
              let args;
              try {
                // Log the raw arguments to debug null byte issues
                if (toolCall.function.arguments.includes('\\0') || toolCall.function.arguments.includes('\\u0000')) {
                  console.warn('[DEBUG] Tool call arguments contain null byte escape sequences:', {
                    hasBackslashZero: toolCall.function.arguments.includes('\\0'),
                    hasUnicodeZero: toolCall.function.arguments.includes('\\u0000'),
                    preview: toolCall.function.arguments.substring(0, 200)
                  });
                }

                args = JSON.parse(toolCall.function.arguments);

                // Check if parsed code contains null bytes
                if (args.code && (args.code.includes('\0') || args.code.includes('\u0000'))) {
                  console.error('[DEBUG] Parsed code contains null bytes! This will cause execution errors. Removing them.');
                  console.error('[DEBUG] Code preview with null bytes:', JSON.stringify(args.code.substring(0, 200)));
                  // Remove null bytes from the code
                  args.code = args.code.replace(/\0/g, '').replace(/\u0000/g, '');
                }
              } catch (error) {
                console.error('Error parsing tool call arguments:', error);
                yield {
                  type: 'error',
                  content: `Error parsing tool call arguments: ${error instanceof Error ? error.message : 'Unknown error'}`,
                  error: error instanceof Error ? error : new Error('Error parsing tool call arguments')
                };
                continue;
              }

              const code = args.code;
              const script_id = args.script_id || completionId;

              yield {
                type: 'function_call',
                name: 'runCode',
                arguments: args,
                call_id: toolCall.id
              };

              // Add the assistant message with tool call to the conversation
              messages.push({
                role: 'assistant',
                content: accumulatedResponse || undefined,
                tool_calls: [{
                  id: toolCall.id,
                  type: 'function',
                  name: 'runCode',
                  function: {
                    name: 'runCode',
                    arguments: toolCall.function.arguments
                  }
                }]
              });

              // On Streaming about executing the code
              if(onStreaming){
                onStreaming(completionId, `Executing code...`);
              }

              // Execute the tool call
              try {
                const result = await onExecuteCode(script_id, code);

                // Yield the tool call output
                yield {
                  type: 'function_call_output',
                  content: result,
                  call_id: toolCall.id
                };

                // Add tool response to messages
                messages.push({
                  role: 'tool',
                  tool_call_id: toolCall.id,
                  content: result
                });
              } catch (error) {
                console.error('Error executing code:', error);
                const errorMessage = `Error executing code: ${error instanceof Error ? error.message : 'Unknown error'}`;

                yield {
                  type: 'error',
                  content: errorMessage,
                  error: error instanceof Error ? error : new Error(errorMessage)
                };

                // Add error message to messages so the model can attempt recovery
                messages.push({
                  role: 'tool',
                  tool_call_id: toolCall.id,
                  content: `Error: ${error instanceof Error ? error.message : 'Unknown error'}`
                });
              }
            } else if (toolCall.function.name === 'commitCodeBlocks') {
              // Handle commitCodeBlocks tool call
              // Parse the arguments
              let args;
              try {
                args = JSON.parse(toolCall.function.arguments);
              } catch (error) {
                console.error('Error parsing commitCodeBlocks arguments:', error);
                yield {
                  type: 'error',
                  content: `Error parsing commitCodeBlocks arguments: ${error instanceof Error ? error.message : 'Unknown error'}`,
                  error: error instanceof Error ? error : new Error('Error parsing commitCodeBlocks arguments')
                };
                continue;
              }

              const code_block_ids = args.code_block_ids || [];

              console.log('DEBUG: commitCodeBlocks called with ids:', code_block_ids, 'message:', accumulatedResponse);

              // Call onMessage with the final message and commit IDs
              if(onMessage){
                onMessage(completionId, null, code_block_ids);
              }

              yield {
                type: 'text',
                content: accumulatedResponse
              };

              // Exit the loop since we have a final response
              return;
            }
          }
        } else {
          // No tool calls - this is a final response
          if (accumulatedResponse) {
            if(onMessage){
              onMessage(completionId, accumulatedResponse, []);
            }
            yield {
              type: 'text',
              content: accumulatedResponse
            };
          }
          // Exit the loop since we have a final response
          return;
        }

        // Add a reminder message if we are approaching the max steps
        if(loopCount >= maxSteps - 2){
          messages.push({
            role: 'user',
            content: `You are approaching the maximum number of steps (${maxSteps}). Please use the commitCodeBlocks tool to commit your working code and provide a final message, otherwise the session will be aborted and no code will be saved.`
          });
        }

        // Check if we've hit the loop limit
        if (loopCount >= maxSteps) {
          console.warn(`Chat completion reached maximum loop limit of ${maxSteps}`);
          const maxStepsMessage = `Reached maximum number of tool calls (${maxSteps}). The session was terminated without committing code blocks, so no code will be visible or saved. Please try breaking your request into smaller steps.`;
          if(onMessage){
            onMessage(completionId, maxStepsMessage, []);
          }
          yield {
            type: 'text',
            content: maxStepsMessage
          };
          break;
        }
      } catch (error: unknown) {
        console.error('Error parsing or processing response:', error);
        let errorMessage = 'Failed to process the model response';

        if (error instanceof Error) {
          errorMessage = `Error: ${error.message}`;
        }

        yield {
          type: 'error',
          content: errorMessage,
          error: error instanceof Error ? error : new Error(errorMessage)
        };

        // Try to add a message to recover if possible
        messages.push({
          role: 'user',
          content: `Error in processing: ${errorMessage}. Please try again with a simpler approach.`
        });
      }
    }
  } catch (err) {
    console.error('Error in structured chat completion:', err);
    const errorMessage = `Chat completion error: ${err instanceof Error ? err.message : 'Unknown error'}`;

    yield {
      type: 'error',
      content: errorMessage,
      error: err instanceof Error ? err : new Error(errorMessage)
    };
  }
}
